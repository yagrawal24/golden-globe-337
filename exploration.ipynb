{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from ftfy import fix_text \n",
    "import unidecode\n",
    "from langdetect import detect, detect_langs\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(r'C:\\Users\\rockm\\golden-globe-337\\gg2013.json')['text']\n",
    "df = pd.read_json('gg2013.json')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    JLo's dress! #eredcarpet #GoldenGlobes\n",
       "1         What's making Sofia Vergara's boobs stay like ...\n",
       "2         RT @FabSugar: Kerry Washington is EVERYTHING. ...\n",
       "3            Anne Hathaway has got me living. #GoldenGlobes\n",
       "4         Jennifer Lopez's lace dress? Thoughts? #Golden...\n",
       "                                ...                        \n",
       "174638    RT @authorViviAnna: I was sad that Mandy Patin...\n",
       "174639    RT @_ItzelMartinez_: Jennifer Lawrence aceptan...\n",
       "174640    Golden Globes, lots of fashion messes...but gl...\n",
       "174641    Did they have mug shots at the golden globes?!...\n",
       "174642    Says @BenAffleck: \"I also didn't get the Actin...\n",
       "Name: text, Length: 174643, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = fix_text(text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|pic.twitter\\S+', '', text)\n",
    "    # Remove emojis\n",
    "    # new_text = unidecode(text)\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    \n",
    "    text = re.sub(r'[^A-Za-z0-9@ \"]+', '', text)\n",
    "    \n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # if text.str.strip() != '':\n",
    "    #     detect(text.split(' ')[0])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = df[df.str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv('text_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_csv('text_cleaned.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1462      rt @possessionista if jennifer lawrence starts...\n",
       "2944      id watch the but scripted tv wins out over awa...\n",
       "6441      golden globes 2013 list of winners from this y...\n",
       "6932                      bill murray wins the beard award \n",
       "8152      the begins hope django unchained wins an award...\n",
       "                                ...                        \n",
       "173191    rt @instyle looking every bit a winner stopped...\n",
       "173233    golden globes 2013 british stars take home awa...\n",
       "173291    golden globes 2013 british stars take home awa...\n",
       "173330    rt @thr complete list of the winners at the 70...\n",
       "173387    winner at our @goldenglobes party practice rou...\n",
       "Name: text, Length: 646, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[cleaned_data.apply(lambda x: re.search('(?=.*award|AWARD)(?=.*wins|Wins|WINS|winner|WINNER).*', x) != None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_data = cleaned_data[cleaned_data.apply(lambda x: re.search('(wins|Wins|WINS|winner|WINNER)', x) != None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125       \"@gustavocadile oscar winner actress anjelica ...\n",
       "349       too busy for the this go around somebody tweet...\n",
       "549       jessica chastain looks like the mozilla firefo...\n",
       "607       lmao \"@morocca hey nbc shouldve gotten a \"mani...\n",
       "619       rt @morocca hey nbc shouldve gotten a \"mani ca...\n",
       "                                ...                        \n",
       "173394    les miserables best picture musical or comedy ...\n",
       "173408    listen to winners from the golden globes adele...\n",
       "173439    jessica chastain best actress drama winner at ...\n",
       "173460    all of the tv award winners at the are on cabl...\n",
       "173466    rt @piersmorgan great amusingly hosted memorab...\n",
       "Name: text, Length: 7495, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = \"rt @galaxiemag lifetime achievement award winner jodie foster is 50 she has been acting for 47 of those years amazing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleged_winner = \"\"\n",
    "subject = []\n",
    "actual_winner = \"\"\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(test_tweet)\n",
    "\n",
    "def extract_entities_2(doc):\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "for ent in extract_entities_2(doc):\n",
    "    if ent[1] == \"PERSON\":\n",
    "        alleged_winner = ent[0]\n",
    "\n",
    "# for token in doc:\n",
    "#     if (token.dep_ == 'nsubj'):\n",
    "#         nsubj = token.text\n",
    "#     elif (token.dep_ == 'dobj'):\n",
    "#         dobj = token.text\n",
    "\n",
    "for token in doc:\n",
    "    # extract subject\n",
    "    if (token.dep_ == 'nsubj'):\n",
    "        subject.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern(word, text): \n",
    "    pat = re.compile(re.escape(word), re.IGNORECASE) \n",
    "    return bool(re.search(pat, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jodie foster\n"
     ]
    }
   ],
   "source": [
    "entities = extract_entities_2(doc)\n",
    "for s in subject:\n",
    "    for e, _ in entities:\n",
    "        if pattern(s, e):\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(jodie foster, 50, 47)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def get_winner(text):\n",
    "    alleged_winner = \"\"\n",
    "    subject = []\n",
    "    actual_winner = \"\"\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "    # for ent in entities:\n",
    "    #     if ent[1] == \"PERSON\":\n",
    "    #         alleged_winner = ent[0]\n",
    "            \n",
    "    for token in doc:\n",
    "        # extract subject\n",
    "        if (token.dep_ == 'nsubj'):\n",
    "            subject.append(token.text)\n",
    "    \n",
    "    entities = extract_entities_2(doc)\n",
    "    for s in subject:\n",
    "        for e, _ in entities:\n",
    "            if pattern(s, e):\n",
    "                return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7495"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(win_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lmao \"@morocca hey nbc shouldve gotten a \"mani cam\" e wins this round '"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_data[607]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125       anjelica huston\n",
       "349                  None\n",
       "549      jessica chastain\n",
       "607                   nbc\n",
       "619           rt @morocca\n",
       "               ...       \n",
       "18022                None\n",
       "18072                None\n",
       "18088        maggie smith\n",
       "18248        maggie smith\n",
       "18287                None\n",
       "Name: text, Length: 250, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_data.head(250).apply(get_winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_data = cleaned_data[cleaned_data.apply(lambda x: re.search('(nominee|nominate|nominated|nominees)', x) != None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49        rt @lokipage times we wish good luck tonight t...\n",
       "61        rt @twittermovies nominee @officialadele on th...\n",
       "154       ive seen a grand total of one nominated film s...\n",
       "338       rt @zap2itrick can kerry washington be nominat...\n",
       "505       rt @twittermovies nominee @officialadele on th...\n",
       "                                ...                        \n",
       "173059    the were amazing im so happy argo won but i th...\n",
       "173107    rt @oskrnyc \"7 cajas\" should have been nominat...\n",
       "173130    \"@itsjerrah i should be nominated as best acto...\n",
       "173172    congrats to all the 2013 golden globes winners...\n",
       "173203    rt @mapeel yes should have been nominated for ...\n",
       "Name: text, Length: 1385, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nom_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gg337",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
